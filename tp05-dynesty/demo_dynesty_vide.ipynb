{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# _Nested sampling_ avec _dynesty_\n",
    "\n",
    "## Prior transforms\n",
    "\n",
    "Le concept de _prior transform_ est un peu moins intuitif que celui d'une distribution à priori (_prior_) comme celle utilisée dans un MCMC. Dans un MCMC, la distribution $\\pi(\\theta)$ est définie **explicitement** en fonction du vecteur de paramètres $\\theta$.\n",
    "\n",
    "Dans le cas du _nested sampling_, les échantillons sont toujours tirés d'un espace uniforme. Il faut donc spécifier une transformation du cube unitaire en $D$ dimensions vers l'espace de paramètres qui nous intéresse (par exemple, un paramètre uniforme entre -100 et 100, un autre gaussien centré sur 0 avec un écart-type de 10). Pour des paramètres indépendants, il suffit d'utilier la distribution cumulative inverse, plus souvent appelée \"fonction quantile\" ou encore \"_percent point function_\", en anglais. Il est aussi possible de définir des corrélations ou des conditions entre les paramètres. La [section dédiée aux prior transforms](https://dynesty.readthedocs.io/en/latest/quickstart.html#prior-transforms) de la documtentation de _dynesty_ donne plus d'information à ce sujet.\n",
    "\n",
    "Pour explorer un peu plus les _prior transforms_, nous allons considérer deux paramètres: l'un ayant un prior uniforme $U(-10, 10)$ et un autre ayant un prior gaussien $\\mathcal{N}(5.0, 1.0)$. En général, un _prior transform_ uniforme est assez simple à implémenter manuellement: il suffit de le re-centrer et de le multiplier pour avoir la bonne largeur (car le point de départ est déjà uniforme, mais sur l'intervalle $U(0, 1)$). Pour la majorité des autres distributions (par exemple une gaussienne ou une distribution uniforme en log), le plus simple sera d'utiliser `scipy.stats` avec la fonction `ppf()`. L'exemple plus bas utilise cette méthode pour la distribution gaussienne.\n",
    "\n",
    "Pour ce premier exemple, on ne fera aucun échantillonage. Le but est juste de vérifier que nos fonctions de _prior transform_ font ce à quoi on s'attend (en général, c'est une bonne habitude de faire cette vérification la première fois qu'on utilise une distribution si on a un doute).\n",
    "\n",
    "Commençons donc par définir notre fonction `prior_transform()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "\n",
    "plt.style.use('tableau-colorblind10')\n",
    "rcParams[\"font.size\"] = 18\n",
    "rcParams[\"figure.figsize\"] = (9, 6)\n",
    "rcParams[\"xtick.direction\"] = \"in\"\n",
    "rcParams[\"ytick.right\"] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "from numpy.random import default_rng\n",
    "\n",
    "def prior_transform(u):\n",
    "    \n",
    "    p = np.array(u)\n",
    "    \n",
    "    # TODO: Définir les transformations\n",
    "    \n",
    "    return p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Générons d'abord des points sur un carré unitaire et vérifion la distribution avec `corner`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant, `prior_transform()` devrait transformer les distributions $U(0, 1)$ vers notre espace de paramètre définit plus haut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme prévu, les distributions sont transformées vers nos _priors_ !\n",
    "\n",
    "## Exemple de comparaison de modèle.\n",
    "\n",
    "Supposons qu'on obtient des observations quelconques. On veut savoir si les données sont mieux représentées par une parabole ou bien si une droite suffit. On peut utiliser les mêmes données simulées que dans le tutoriel `emcee` de la semaine dernière."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "\n",
    "# Choose the \"true\" parameters.\n",
    "m_true = -0.9594\n",
    "b_true = 4.294\n",
    "f_true = 0.534\n",
    "\n",
    "# Generate some synthetic data from the model.\n",
    "N = 50\n",
    "x = np.sort(10 * np.random.rand(N))\n",
    "yerr = 0.1 + 0.5 * np.random.rand(N)\n",
    "y = m_true * x + b_true\n",
    "y += yerr * np.random.randn(N)\n",
    "\n",
    "plt.errorbar(x, y, yerr=yerr, fmt=\".k\", capsize=0)\n",
    "x0 = np.linspace(0, 10, 500)\n",
    "plt.plot(x0, m_true * x0 + b_true, \"k\", alpha=0.3, lw=3)\n",
    "plt.xlim(0, 10)\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Model 1: Droite\n",
    "\n",
    "On teste d'abord la droite en utilisant les mêmes _priors_ que dans le tutoriel d'emcee (en général on voudrait un _prior_ uniforme en log pour les paramètres d'amplitude, mais une distribution uniforme fera l'affaire ici)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndim = 2\n",
    "\n",
    "def log_likelihood(theta, x, y, yerr):\n",
    "    # TODO: Log likelihood\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ptform_line(u):\n",
    "    \n",
    "    p = np.array(u)\n",
    "    \n",
    "    # TODO: Générer les transformations\n",
    "    \n",
    "    return p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une fois le modèle et le _prior_ définis, on peut utiliser `dynesty` pour faire un _nested sampling_ dynamique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dynesty\n",
    "\n",
    "# TODO: Utiliser dynesty pour exécuter un Nested sampling dynamique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les graphiques inclus dans dynesty peuvent nous informer sur l'échantillonage et sur l'évolution des points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dynesty import plotting as dyplot\n",
    "\n",
    "# TODO: Utiliser dynesty pour afficher différents graphqiques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensuite, on peut calculer l'évidence et d'autres informations qui nous intéressent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dynesty import utils as dyfunc\n",
    "\n",
    "# TODO: Calculer les valeurs des paramètres (quantiles) et de l'évidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantiles = np.array(quantiles)\n",
    "for i in range(ndim):\n",
    "    print(quantiles[i, 1], \"+\", quantiles[i, 2] - quantiles[i, 1], \"-\", quantiles[i, 1] - quantiles[i, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_line, b_line = quantiles[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.errorbar(x, y, yerr=yerr, fmt=\".k\", capsize=0)\n",
    "x0 = np.linspace(0, 10, 500)\n",
    "plt.plot(x0, m_true * x0 + b_true, \"k\", alpha=0.3, lw=3)\n",
    "plt.plot(x0,  m_line* x0 + b_line, \"b\", alpha=0.3, lw=3)\n",
    "plt.xlim(0, 10)\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Model 2: Parabole\n",
    "On peut maintenant répéter toute la procédure avec une parabole au lieu d'une droite. Par inspection visuelle, il semble que garder le premier coefficient entre -0.1 et 0.1 soit bien suffisant. On utilisera donc ce _prior_ uniforme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndim = 3\n",
    "\n",
    "def log_likelihood(theta, x, y, yerr):\n",
    "    # TODO: parabole\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ptform(u):\n",
    "    \n",
    "    p = np.array(u)\n",
    "    \n",
    "    # TODO: Transformer les parmètres\n",
    "    \n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dynesty\n",
    "\n",
    "# TODO: Effectuer le nested sampling pour la parabole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Générer les graphiques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dynesty import utils as dyfunc\n",
    "\n",
    "# TODO: Calculer les paramètres et l'évidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantiles = np.array(quantiles)\n",
    "for i in range(ndim):\n",
    "    print(quantiles[i, 1], \"+\", quantiles[i, 2] - quantiles[i, 1], \"-\", quantiles[i, 1] - quantiles[i, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_para, m_para, b_para = quantiles[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.errorbar(x, y, yerr=yerr, fmt=\".k\", capsize=0)\n",
    "x0 = np.linspace(0, 10, 500)\n",
    "plt.plot(x0, m_true * x0 + b_true, \"k\", alpha=0.3, lw=3)\n",
    "plt.plot(x0,  m_line* x0 + b_line, \"b\", alpha=0.3, lw=3)\n",
    "plt.plot(x0,  a_para * x0**2 + m_para* x0 + b_para, \"r\", alpha=0.3, lw=3)\n",
    "plt.xlim(0, 10)\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparaison des modèles\n",
    "\n",
    "On peut maintenat utiliser le tableau de Trotta (2008) pour comparer les modèles:\n",
    "\n",
    "<img src=\"table1_trotta.png\" width=500 height=400 />\n",
    "\n",
    "Grâce aux évidences calculées ci-haut, on a:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Calculer le Bayes factor"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
