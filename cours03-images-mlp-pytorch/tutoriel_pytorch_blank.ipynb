{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b86e4193-e742-469d-aac9-5982b44e0d34",
   "metadata": {},
   "source": [
    "# Classification d'images avec un réseau pleinement connecté et PyTorch\n",
    "\n",
    "Au dernier TP, nous avons exploré les bases de PyTorch pour une régression linéaire et un tout petit réseau neuronal (XOR).\n",
    "\n",
    "Nous aurons besoin de PyTorch pour ce Notebook. S'il n'est pas déjà installé, référez vous au dernier TP pour le faire.\n",
    "\n",
    "Nous aurons aussi besoin d'opencv pour manipuler certaines images. Vous pouvez l'installer avec `pip install opencv-python`.\n",
    "\n",
    "Aujourd'hui, nous verrons un cas plus réaliste où le but est de classifier des données.\n",
    "Nous allons créer un réseau de neurones simple pour classifier des images de la base de données « [Fashion MNIST](https://github.com/zalandoresearch/fashion-mnist) ».\n",
    "Cet ensemble a été créé pour fournir une alternative à la base de données MNIST (les chiffres écrits à la main).\n",
    "Nous allons utiliser cet exemple car il est assez rapide à analyser pour le faire sur CPU, et aussi car un perceptron multi-couche (_MLP_) simple\n",
    "performe relativement bien sur ces images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8c5325",
   "metadata": {},
   "source": [
    "## Données\n",
    "\n",
    "Contrairement à ce que nous avons fait depuis le début de la session, où l'on performait principalement des tâches de _régression_, l'exemple ci-dessous s'intéresse à la classification.\n",
    "Pour les problèmes de classification, les données sont souvent des images.\n",
    "Numériquement, une image n'est rien d'autre qu'un tableau (tenseur) avec des valeurs numériques.\n",
    "Elles ont typiquement 3 dimensions: `(couleur, X, Y)`. La dimension de couleur a généralement une longueur de 3 pour une image RGB (itensité de chaque pixel en rouge, bleu et vert).\n",
    "Pour une image à une seule couleur (en noir et blanc), la dimension couleur aura une longueur 1.\n",
    "\n",
    "### Téléchargement avec PyTorch\n",
    "\n",
    "PyTorch inclut une classe `Dataset` qui permet d'organiser efficacement des données, incluant les catégories pour les données de test et d'entraînement.\n",
    "On peut définir un `Dataset` avec nos propres données, mais pour les tests ou les exmples, PyTorch inclut des ensembles de données pré-définis.\n",
    "On peut donc télécharger et importer les données _MNIST Fashion_ directement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f12cb2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torchvision import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e020f41f-584b-4cd9-9f01-f1c3ecdd018b",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",  # Dir où on va sauvegarder les données\n",
    "    train=True,  # Pour dataset existant, train=True importe les données d'entraînement\n",
    "    download=True,  # On laisse PyTorch télécharger les données en ligne au besoin\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc0c62b-d760-41dc-9b5c-2073e322c4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1c79da-55b9-4c3f-98e2-03cfc309af6e",
   "metadata": {},
   "source": [
    "`training_data` est un object `Dataset` qui contient 60 000 images.\n",
    "On aurait également pu accéder au nombre d'images avec `len(training_data)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa25cf19-c770-49f8-bcb7-456f3b3b3b68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Le dataset comporte un tenseur et un label par élément\n",
    "print(training_data)\n",
    "print(\"Nombre d'images:\", len(training_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a613a920-a666-40d1-8e38-b9433ad7be29",
   "metadata": {},
   "source": [
    "### Images en Python et librairie PIL (Pillow)\n",
    "\n",
    "Pour accéder au premier élément, on utilise la syntaxe Python habituelle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb60e9fa-2f39-48e8-9726-526f97f3b2da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad50bce-23a8-4fa8-9298-50d96ca3bb6b",
   "metadata": {},
   "source": [
    "On voit que chaque exemple ne contient pas seulement l'image, mais aussi un chiffre. Ce chiffre dénote la classe à laquelle l'image appartient.\n",
    "Pour connaître la signification de chaque chiffre, on peut se référer à [la page GitHub de Fashion MNIST](https://github.com/zalandoresearch/fashion-mnist?tab=readme-ov-file#labels).\n",
    "On peut mettre le tout dans un dictionnaire pour facilement identifier les objets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3212b38f-dcda-4975-abad-1ce864588830",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_map = {\n",
    "    0: \"T-Shirt\",\n",
    "    1: \"Trouser\",\n",
    "    2: \"Pullover\",\n",
    "    3: \"Dress\",\n",
    "    4: \"Coat\",\n",
    "    5: \"Sandal\",\n",
    "    6: \"Shirt\",\n",
    "    7: \"Sneaker\",\n",
    "    8: \"Bag\",\n",
    "    9: \"Ankle Boot\",\n",
    "}\n",
    "inv_labels_map = dict(zip(labels_map.values(), labels_map.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bcd86e1-b8dc-4cd5-a4dd-bf14da3de92b",
   "metadata": {},
   "source": [
    "Quant au premier élément du tuple ci-dessus, il s'aggit d'une image au format « Python Image Library » (PIL ou `pillow`).\n",
    "Cette librarie permet de manipuler des images en Python ([tutoriel ici](https://pillow.readthedocs.io/en/stable/handbook/tutorial.html#)).\n",
    "Dans notre cas, nous convertirons généralement les images vers des tenseurs PyTorch, mais explorons d'abord un peu Pillow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60129279-6923-45ba-8265-e167b6ecefba",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_img, example_label = training_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d72b1c-3a0a-4edb-8948-0164ba97a6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Type d'article:\", labels_map[example_label])\n",
    "print(\"Infos sur l'image:\", example_img.format, example_img.size, example_img.mode)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47bcaf0c-1c72-480b-91cf-fdfb22a1b997",
   "metadata": {},
   "source": [
    "Les informations ci-dessus nous donnent le format d'entrée (None ici comme PyTorch avait compressé l'image), la taille de l'image et le mode (L pour noir et blanc, RGB pour couleurs).\n",
    "\n",
    "Pour afficher l'image, on peut utiliser Matplotlib directement.\n",
    "On utilise `cmap=\"binary\"` pour des couleurs plus intuitives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c499223-3b91-40cf-a309-2fe91a95fb0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(example_img, cmap=\"binary\")\n",
    "plt.title(labels_map[example_label])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a9a7b79-dbab-4539-8767-3937736c0cca",
   "metadata": {},
   "source": [
    "Pillow nous permet aussi de faire certaines transormations de base avec nos images, par exemple un découpage ou une rotation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e0653c-6a77-49ad-b324-a3137ca797ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(example_img.rotate(45), cmap=\"binary\")\n",
    "plt.title(\"Rotated \" + labels_map[example_label])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c517f5-e3f0-49b8-a133-336d7825d647",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(example_img.crop((10, 5, 20, 20)), cmap=\"binary\")\n",
    "plt.title(\"Cropped \" + labels_map[example_label])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443d8434-f5ae-4a6b-ad86-8216130e22a5",
   "metadata": {},
   "source": [
    "Et on peut convertir les données vers un tableau NumPy.\n",
    "Pour une image en noir et blanc, on aura un tableau 28x28 avec des valeurs entre 0 et 255.\n",
    "Pour une image RGB, le format aurait été `(3, 28, 28)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeef9198-6708-43fc-a8f0-ac9566e01f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "img_arr = np.array(example_img)\n",
    "print(img_arr.shape)\n",
    "print(img_arr.min(), img_arr.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b928ed-19d3-4c23-bcb8-18617f7c5917",
   "metadata": {},
   "source": [
    "### Images avec PyTorch\n",
    "\n",
    "Pour utiliser les images dans un modèle PyTorch, on doit les convertir en tenseur.\n",
    "L'utilité `ToTensor()` nous permet de le faire facilement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad3ed20-7bb9-4332-b2fe-8760689b3c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a1aa4d-9ad4-4653-a6fd-7764d795c58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_converter = ToTensor()\n",
    "img_tensor = img_converter(example_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8005579-dc24-42de-839f-403e0017a8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(img_tensor.shape)\n",
    "print(img_tensor.min(), img_tensor.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9cb5e0-bbbc-464d-8b8a-c41371890e75",
   "metadata": {},
   "source": [
    "On remarque deux choses:\n",
    "\n",
    "- PyTorch inclut toujours la dimension de couleur, donnant `(1, 28, 28)`.\n",
    "- PyTorch normalise les images entre 0 et 1.\n",
    "\n",
    "**On peut appliquer la transformation `ToTensor()` à tous nos exemples automatiquement.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f739a700-716b-49f9-8e2a-6872e9119adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",  # Dir où on va sauvegarder les données\n",
    "    train=True,  # Pour dataset existant, train=True importe les données d'entraînement\n",
    "    download=True,\n",
    "    transform=ToTensor(),  # Transformation de tableau PIL vers tenseur\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774edbd2-407a-416a-835f-ca5af1b2f60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532499cb-c931-4f71-b224-3e4a1263d0b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(type(training_data[0][0]))\n",
    "print(training_data[0][0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1378322-733d-47dd-a473-70be0c00d996",
   "metadata": {},
   "source": [
    "Remarquez l'argument `train=True` ci-dessus.\n",
    "Il dit à PyTorch de n'importer que les données d'entraînement dans notre ensemble.\n",
    "Avec `train=False`, on peut importer les données test.\n",
    "\n",
    "**Exercice: Importez les données test dans un objet `test_data` et imprimez l'ensemble.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d4f051",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO: Test data & print"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7432cb78-bf70-4fa5-8b92-3744a0c29c35",
   "metadata": {},
   "source": [
    "On peut également afficher les données directement à partir du format PyTorch.\n",
    "Par contre, Matplotlib s'attend à ce que la dimension « couleur » soit en 3e, pas en 1er...\n",
    "On a donc deux choix: utiliser l'image 2D (OK pour des données noir et blanc) ou réordonner les axes avec `permute()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a821a869",
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Ici, on envoie l'axe 0 en dernière position et on garde 1 et 2 dans l'ordre initial.\n",
    "plt.imshow(training_data[1][0].permute(1, 2, 0), cmap=\"binary\")\n",
    "plt.title(labels_map[training_data[1][1]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5cfba4-4853-49f2-b21d-5112eea1d2d5",
   "metadata": {},
   "source": [
    "On peut se définir une fonction qui affichera des images pour le reste du Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638e3311-a024-4f3d-a456-f6c39f09dc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def plot_grid(data):\n",
    "    \"\"\"\n",
    "    Fonction pour tirer 9 images au hasard d'un Dataset PyTorch et les fafficher\n",
    "    \"\"\"\n",
    "    figure = plt.figure(figsize=(8, 8))\n",
    "    cols, rows = 3, 3\n",
    "    for i in range(1, cols * rows + 1):\n",
    "        # On tire une image au hasard et on l'affiche\n",
    "        sample_idx = torch.randint(len(data), size=(1,)).item()\n",
    "        img, label = data[sample_idx]\n",
    "        figure.add_subplot(rows, cols, i)\n",
    "        plt.title(labels_map[label])\n",
    "        plt.axis(\"off\")\n",
    "        plt.imshow(img.permute(1, 2, 0), cmap=\"binary\")\n",
    "    return figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66a60b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_grid(training_data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb892f1",
   "metadata": {},
   "source": [
    "### Dataloader: séparer les données en sous-ensembles\n",
    "\n",
    "Le `Dataset` organise déjà les images en ensemble d'entraînement et de test, mais ne permet pas de les séparer en sous-ensembles (_batches_) ou de les mélanger avant l'entraînement.\n",
    "Pour ce faire, on utilise la classe `Dataloader`. Cette dernière prend un `Dataset` en entrée et le sépare en sous-ensemble.\n",
    "\n",
    "En créant les `DataLoader` ci-dessous, on spécifie en argument:\n",
    "\n",
    "- L'ensemble de données\n",
    "- La taille des sous-ensembles (nombre d'images analysées pour chaque pas de la descente de gradient)\n",
    "- `suffle=True` pour re-brasser les sous-ensembles à chaque époque."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb2aa3e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size=64, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119067f5-2bb3-4772-b914-f82925cf67dd",
   "metadata": {},
   "source": [
    "On peut vérifier le nombre de sous-ensembles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115a705c-e749-439a-8598-05a90980fea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Nombre de sous-ensembles pour l'entraînement:\", len(train_dataloader))\n",
    "print(\"Nombre de sous-ensembles pour la phase test:\", len(test_dataloader))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844092d9-91f1-4d3a-916e-c6dc9e842389",
   "metadata": {},
   "source": [
    "On peut voir que les 60 000 exemples d'entraînement on été séparés en groupes de 64 (sauf pour le dernier).\n",
    "\n",
    "On peut aussi essayer d'accéder aux données..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f3b87a-0452-46d9-875f-30552e95d70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    train_dataloader[0]\n",
    "except Exception as e:\n",
    "    print(\"Erreur:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e52d19f-7eff-488d-8d0e-82361cb37bee",
   "metadata": {},
   "source": [
    "Comme on peut voir ici, on ne peut pas simplement indexer le `Dataloader`.\n",
    "La façon de s'en servir est normalement avec une boucle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071cae12-236f-40bf-91c2-56be01981166",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, batch in enumerate(train_dataloader):\n",
    "    if i == 0:\n",
    "        print(\"Premier sous-ensemble\")\n",
    "        print(\"  Type du sous-ensemble\", type(batch))\n",
    "        print(\"  Longueur du sous-ensemble\", len(batch))\n",
    "        print(\"  Format des images:\", batch[0].shape)\n",
    "        print(\"  Format des annotations\", batch[1].shape)\n",
    "    elif i == (len(train_dataloader) - 1):\n",
    "        print()\n",
    "        print(\"Dernier sous-ensemble:\")\n",
    "        print(\"  Forrmat des images:\", batch[0].shape)\n",
    "    else:\n",
    "        print(\".\", end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747152ca",
   "metadata": {},
   "source": [
    "Pour accéder à un seul exemple du `Dataloader`, on peut créer un itérateur avec `iter()` et lui demander le prochain exemple avec `next()`.\n",
    "Ce processus est similaire à ce que fait la boucle `for` normalement.\n",
    "\n",
    "On peut ainsi accéder à un seul sous-ensemble sans faire une boucle.\n",
    "Et comme nous avons spécifié `shuffle=True`, on obtient un rebrassage à chaque fois que l'on utilise `iter()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d29eff3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_features, train_labels = next(iter(train_dataloader))\n",
    "print(f\"Format des images: {train_features.size()}\")\n",
    "print(f\"Format des annotations: {train_labels.size()}\")\n",
    "\n",
    "# On extrait le premier exemple du sous-ensemble\n",
    "img = train_features[0].squeeze()  # On laisse tomber la dimension \"couleur\"\n",
    "label = train_labels[0]\n",
    "plt.imshow(img, cmap=\"binary\")\n",
    "plt.title(labels_map[train_labels[0].item()])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6666bf5",
   "metadata": {},
   "source": [
    "## Définition d'un modèle\n",
    "\n",
    "Les données sont bien formattées.\n",
    "On peut maintenant passer à la définition et l'entraîenement d'un modèle!\n",
    "\n",
    "On pourrait définir un réseau avec les éléments de base de PyTorch, c'est à dire des tenseurs, de l'algèbre matriciel et `autograd`.\n",
    "Par contre, tel que vu au dernier cours, PyTorch nous rend la vie plus facile avec la librairie `torch.nn`, qui fait les opérations générales à notre place.\n",
    "On peut donc définir notre modèle sans écrire explicitement toutes les opérations, mais en nous concentrant plutôt sur la structure.\n",
    "\n",
    "Si vous voulez voir comment on implémenterait un réseau sans `torch.nn`, ce tutoriel PyTorch donne un exemple intéressant: https://pytorch.org/tutorials/beginner/nn_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62a5c0e",
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "277284ee",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "Nous avons vu au dernier cours que `torch.nn` utilise une interface orientée objet: les modèles sont des _classes_ et on implémente des _méthodes_ pour créer le modèle.\n",
    "\n",
    "### Programmation orientée objet: rappel rapide\n",
    "\n",
    "La définition d'un modèle avec `torch.nn` requiert des connaissances de base de la programmation orientée objet:\n",
    "- Une classe est un type d'objet (comme `int`, `bool` ou `torch.Tensor`) que l'on définit nous mêmes\n",
    "- Les classes ont des attributs et des méthodes (fonction qui agissent sur l'objet, comme `\"point\".replace(\"t\", \"g\")` qui retourne \"poing\")\n",
    "- `nn.Module` est une classe de base pour les modèles PyTorch. Elle définit les différentes opérations de bases d'un réseau de neurones\n",
    "- On peut créer une sous-classe qui héritera de ces caractéristiques, tout en y ajoutant de nouvelles caractéristiques plus spécifiques\n",
    "- La méthode `__init__` est la méthode qui permet de créer un objet (ce qui serait exécuté quand on utilise `a = np.array([1,2,3])` par exemple. `[1,2,3]` est un argument de la fonction `__init__`)\n",
    "\n",
    "### Création d'un réseau pleinement connecté pour la classification d'images\n",
    "\n",
    "#### Couche par couche\n",
    "\n",
    "Dans l'exemple XOR du cours précédent, nous avons vu tous les blocs de base permettant de définir un réseau neuronal pleinement connecté.\n",
    "\n",
    "**Exercice: Implémentez le réseau décrit ci-dessous à l'aide de `torch.nn`.**\n",
    "\n",
    "- On convertit l'image vers un vecteur 1D (entrées $x$) `nn.Flatten()`\n",
    "- Une couche pleinement connectée de 512 neurones (cachée $h_1$)\n",
    "- Une autre couche pleinement connectée de 512 neurones (cachée $h_2$)\n",
    "- Une dernière couche donnant les logits (log-probablité non-normalisée) pour chaque catégorie (sortie $y$)\n",
    "- Activations `nn.ReLU()` pour les couches internes\n",
    "\n",
    "\n",
    "Comme nous avons fait dans l'exemple XOR, définissez les couches et les fonctions dans `__init__()`, puis réutilisez les dans la méthode `forward`.\n",
    "\n",
    "**NOTE: Plus bas nous utiliserons [nn.CrossEntropyLoss](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html) comme fonction objectif. Cette fonction s'attend à des logits en entrée. Nous n'avons donc pas à utiliser nn.Softmax directement ici, car `nn.CrossEntropyLoss` le fait pour nous.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9bcca45",
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SimpleNetworkNoSeq(nn.Module):\n",
    "    def __init__(self):\n",
    "        # TODO: Fonction init\n",
    "        pass\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # TODO: Fonction forward\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a93867-fffa-47c9-93b8-bc6a5c51fa97",
   "metadata": {},
   "source": [
    "Le réseau est implémenté! On peut en créer une instance avec `model_noseq = SimpleNetworkNoSeq()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41bee87c-730f-44f5-9892-cdb2798ef105",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_noseq = SimpleNetworkNoSeq().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e684c06-7f2e-40a3-b2cc-81a5d6b3d30f",
   "metadata": {},
   "source": [
    "**Exercice: Accédez à la 50e image des données d'entraînement et donnez-la en entrée au modèle. Ajoutez une dimension additionnelle à la position 0 avec `.unsqueeze()` pour simuler un sous-ensemble de longueur 1. Affichez la valeur de retour et son format (size).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a623f5-7487-4558-83fe-2c94f2205738",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_example, label_example = training_data[50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75aef073-1d0e-4657-9237-055ca6ab5f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_example = model_noseq(img_example.unsqueeze(0))\n",
    "print(out_example)\n",
    "print(out_example.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666ccfd4-3047-4f5e-ae40-fe872ff321e0",
   "metadata": {},
   "source": [
    "On voit que les « scores » sont donnés en _logits_.\n",
    "Remarquez aussi que `grad_fn` est défini!\n",
    "\n",
    "On peut les convertir vers des probabilités avec `torch.nn.functional.softmax`.\n",
    "Il faut spécifier sur quelle dimension on veut normaliser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538cb6bc-f9ad-4403-b9f2-20df1edc47e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_example = nn.functional.softmax(out_example, dim=1)\n",
    "print(prob_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a6d67cf-0247-4aad-90be-aaf503e5485a",
   "metadata": {},
   "source": [
    "`nn.functional` est une interface fonctionnelle aux objets de `torch.nn`.\n",
    "On aurait également pu utiliser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0004509e-2d2b-45ec-be5e-2be0c51d9deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.Softmax(dim=1)(out_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe73ce7a-dd3a-4a8c-975e-aa8df3250317",
   "metadata": {},
   "source": [
    "**Exercice: Vérifiez que les probabilités sont bien normalisées**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465908b0-5cdd-4342-a54c-fb878343165d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Vérifier normalisation des probabilités"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd009c50",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "#### Implémentation avec `nn.Sequential`\n",
    "\n",
    "Le réseau ci-dessus fonctionne, mais la série d'opérations sur x est un peu répétitive dans `forward()`. \n",
    "C'est le cas pour beaucoup de réseaux.\n",
    "`nn.Sequential` permet de directement définir une chaine d'opérations.\n",
    "On fait appelle à cette chaîne directement dans `forward()`\n",
    "\n",
    "**Consultez la documentation pour nn.Sequential et implémentez le réseau ci-dessus, mais en utilisant `nn.Sequential` pour tout sauf `Flatten`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394d73c4",
   "metadata": {
    "lines_to_next_cell": 1,
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SimpleNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        # TODO: Init avec nn.Flatten et nn.Sequential\n",
    "    def forward(self, x):\n",
    "        # TODO: Calcul des logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87bde0a",
   "metadata": {},
   "source": [
    "#### Comparaison des deux implémentations\n",
    "\n",
    "Mathématiquement, les deux modèles devraient faire exactement la même chose.\n",
    "\n",
    "**Exercice: Créez une instance `model` de `SimpleNetowrk`. Imprimez `model` et `model_noseq` pour les comparer. Testez le résultat de `model` sur l'image 50, comme plus haut. Comparez les valeurs de sorties avec le modèle « non séquentiel ». Les valeurs sont-elles les même? Pourquoi?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f987cb8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO: Création de model et test sur l'image img_example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec86023f-4415-46ef-973a-7c90ea851086",
   "metadata": {},
   "source": [
    "Les valeurs sont différentes car les poids utilisés pour initialiser le modèle sont différents: cette initialisation est faite de manière aléatoire.\n",
    "\n",
    "On peut forcer une stratégie d'initialisation des poids avec `nn.init`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7e704e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Pour vérifier les structures, on peut forcer les poids à être identiques\n",
    "def init_const(m):\n",
    "    # Fonction destinée à nn.Model.apply()\n",
    "    # m est une couche du réseau. Si c'est une couche linéaire, on ajuste les paramètres\n",
    "    if isinstance(m, nn.Linear):\n",
    "        # Plusieurs autres distributions disponibles dans le module nn.init\n",
    "        # Ici on utilise des valeurs déterministiques pour notre test\n",
    "        nn.init.constant_(m.bias.data, 0.0)\n",
    "        # matrice identité pour ne pas avoir des activations égales partout\n",
    "        nn.init.eye_(m.weight.data)\n",
    "\n",
    "\n",
    "model.apply(init_const)\n",
    "model_noseq.apply(init_const)\n",
    "print(model(img_example.unsqueeze(0)))\n",
    "print(model_noseq(img_example.unsqueeze(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34209d7b-ed62-44bf-849a-90a435f061f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Réinitialisation du modèle\n",
    "model = SimpleNetwork().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26843909-78c7-4899-b93a-525414ad5da4",
   "metadata": {},
   "source": [
    "**Exercice: Explorez `model.parameters()` et `model.named_parameters()`. Combien de paramètres y a-t-il au total dans le modèle?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e59f725-fc61-43c3-94ff-ec2d85b48222",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fcd24687-a8c9-48f2-933c-ae1269a18cb8",
   "metadata": {},
   "source": [
    "### Prédiction avec le réseau non entraîné\n",
    "\n",
    "Pour l'instant, notre réseau n'est pas entraîné.\n",
    "Il y a tout de même quelques opérations que nous voudrons souvent répéter.\n",
    "Ce serait un bon moment pour implémenter quelques fonctions qui nous aideront à:\n",
    "\n",
    "- Tester le modèle sur une image donnée.\n",
    "- Afficher l'image et les probabilités prédites par le modèle.\n",
    "\n",
    "#### Fonction pour tester le modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc08e878",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def try_model(img, mod):\n",
    "    \"\"\"\n",
    "    Fonction qui teste le modèle et retourne les probabilités pour chaque classe\n",
    "    \"\"\"\n",
    "    logits = mod(img.unsqueeze(0))\n",
    "    pred_probab = nn.Softmax(dim=1)(logits)\n",
    "    y_pred = pred_probab.argmax(1)\n",
    "    print(f\"Catégorie prédite: {labels_map[y_pred.item()]}, probabilité de {pred_probab.max():.3f}\")\n",
    "\n",
    "    return pred_probab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "838efb84-0b51-4351-8845-0ebe952c06d2",
   "metadata": {},
   "source": [
    "**Exercice: Testez le modèle sur une image composée de bruit uniforme générée avec `torch.rand`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6e196d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO: Génération d'une image aléatoire et test du model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eddf4f0d-25dc-464f-a84a-09e860a54c53",
   "metadata": {},
   "source": [
    "#### Fonctions d'affichage\n",
    "\n",
    "Une bonne façon de visualiser la sortie est d'afficher l'image avec un histogramme des probabilités.\n",
    "Les fonctions d'affichage sont tirées de ce tutoriel TensorFlow: https://www.tensorflow.org/tutorials/keras/classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a573784-43c0-4563-bfe8-e0e5149f3d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image(predictions_array, true_label, img, cmap=\"binary\"):\n",
    "    \"\"\"\n",
    "    - predictions_array: Tableau de prédictions (probabilités)\n",
    "    - true_label: vraie annotation/catégorie\n",
    "    - image: Image à afficher\n",
    "    - cmap: Colormap pour Matplotlib\n",
    "    \"\"\"\n",
    "    plt.grid(False)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "    plt.imshow(img, cmap=cmap)\n",
    "\n",
    "    predicted_label = torch.argmax(predictions_array).item()\n",
    "    if predicted_label == true_label:\n",
    "        color = \"blue\"\n",
    "    else:\n",
    "        color = \"red\"\n",
    "\n",
    "    plt.xlabel(\n",
    "        \"{} {:2.0f}% ({})\".format(\n",
    "            labels_map[predicted_label],\n",
    "            100 * torch.max(predictions_array),\n",
    "            \"None\" if true_label is None else labels_map[true_label],\n",
    "        ),\n",
    "        color=color,\n",
    "    )\n",
    "\n",
    "\n",
    "def plot_value_array(predictions_array, true_label):\n",
    "    \"\"\"\n",
    "    Affichage des prédictions dans une histogramme.\n",
    "    \"\"\"\n",
    "    plt.grid(False)\n",
    "    plt.xticks(range(10))\n",
    "    plt.yticks([])\n",
    "    thisplot = plt.bar(range(10), predictions_array.numpy(), color=\"#777777\")\n",
    "    plt.ylim([0, 1])\n",
    "    predicted_label = torch.argmax(predictions_array).item()\n",
    "\n",
    "    thisplot[predicted_label].set_color(\"red\")\n",
    "    if true_label is not None:\n",
    "        thisplot[true_label].set_color(\"blue\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55d08a5-b380-4d57-a068-791ab136c210",
   "metadata": {},
   "source": [
    "On peut tester ces fonctions sur notre image aléatoire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a275fb88",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 3))\n",
    "plt.subplot(1, 2, 1)\n",
    "plot_image(preds.squeeze().detach(), None, X.squeeze().detach())\n",
    "plt.subplot(1, 2, 2)\n",
    "plot_value_array(preds.squeeze().detach(), None)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d8741c",
   "metadata": {},
   "source": [
    "On peut également la tester sur une vraie image\n",
    "\n",
    "**Exercice: Copiez la cellule ci-dessus, mais utilisez une image tirée de l'ensemble d'entraînement et son annotation.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027aa4ef",
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO: Affichage image entraînement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14779bbd",
   "metadata": {},
   "source": [
    "## Entraînement\n",
    "\n",
    "Maintenant que le modèle est définit, on peut l'entraîner pour qu'il puisse mieux classifier les images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c73e9bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Nouveau modèle, pour effacer nos manipulations dans la section d'avant\n",
    "model = SimpleNetwork().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e802b57c",
   "metadata": {},
   "source": [
    "### Sélection des hyperparamètres\n",
    "\n",
    "D'abord, il faut choisir les hyperparamètres (les valeurs pré-définies qui affectenent l'entraînement)\n",
    "- Époques: nombre d'itérations  sur les données complètes\n",
    "- Sous-ensembles: nombre d'exemples donnés aux modèle avant de mettre à jour les paramètres\n",
    "- Learning rate: Taux de changement à chaque mise à jour des paramètres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35334f22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "batch_size = 64\n",
    "learning_rate = 1e-3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db3472c",
   "metadata": {},
   "source": [
    "### Fonction objectif\n",
    "Il faut aussi choisir une fonction objectif qui caractérise la perormance du modèle.\n",
    "`CrossEntropyLoss` combine softmax et negative log-likelihood.\n",
    "Cette fonction distingue mieux les très mauvais modèles des modèles presque adéquats\n",
    "que la fonction \"Mean Square error\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2389ec88",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4306ab48",
   "metadata": {},
   "source": [
    "### Optimiseur\n",
    "\n",
    "L'optimisation se fera avec une descente de gradient stochastique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735d85ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44197ef2",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "### Boucles d'entraînement et test\n",
    "\n",
    "#### Boucle d'entraînement\n",
    "\n",
    "Une fois toutes nos fonction définies on peut faire l'entraînement.\n",
    "\n",
    "**Exercice: Définissez une fonction `train_loop` qui complète une époque d'entraînement en itérant sur `dataloader`. La fonction doit retourner la valeur moyenne de la fonction objectif sur tous les exemples.**\n",
    "\n",
    "Quelques rappels/suggestions:\n",
    "\n",
    "- Insipirez-vous de notre boucle dans l'exemple XOR du dernier cours\n",
    "- Il faut réinitialiser les paramètres à chaque étape, recaclculer le gradient avec PyTorch et faire faire un pas à notre optimiseur.\n",
    "- Vous pouvez afficher la valeur de la fonction objectif à tous les 100 exemples pour suivre l'évolution du modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58f737b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    \"\"\"\n",
    "    Fonction de boucle d'entraînement\n",
    "    - dataloader: Dataloader avec les données d'entraînement\n",
    "    - model: modèle à entraîner\n",
    "    - loss_fn: Fonction objectif\n",
    "    - optimizer: Optimiseur\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9d81be",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "#### Boucle de test (validation)\n",
    "\n",
    "Pour chaque époque de l'entraînement, il sera aussi utile d'itérer sur les données test.\n",
    "La boucle de test vérifie la performance sur des données non utilisées à l'entraînement.\n",
    "On utilise seulement la propagation avant, donc pas besoin des gradients.\n",
    "Cette boucle peut être utilisée à chaque époque pour voir l'évolution de l'entrainement.\n",
    "\n",
    "Remarquez l'utilisation de `torch.no_grad()` qui permet d'éviter la propagation des gradients et de sauver du temps de calcul."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d1b1ce",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test_loop(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss = correct = 0\n",
    "\n",
    "    # On se sauve les gradients comme ils ne sont pas utilisés\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()  # Compute loss\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct)}%, Avg loss: {test_loss} \\n\")\n",
    "\n",
    "    return test_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946c0cbc",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "Une fois les boucles d'entraînement et de test terminées, on peut itérer plusieurs\n",
    "fois sur toutes les données\n",
    "\n",
    "**Exercice: Utilisez les deux fonctions ci-dessus pour itérer sur les époques d'entraînement (`epochs`). Pour chaque époque, sauvegardez la valeur de la fonction objetif.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1b29e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "test_losses = []\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loss = train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    train_losses.append(train_loss)\n",
    "    test_loss = test_loop(test_dataloader, model, loss_fn)\n",
    "    test_losses.append(test_loss)\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3f7abc-c717-4c06-a82f-126c3e319876",
   "metadata": {},
   "source": [
    "**Exercice: Affichez sur en graphique la valeur de la fonction objectif en fonction du nombre d'époques. Affichez la valeur pour les données d'entraînement et de test.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5d9ad8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO: Graphique d'entraînement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65a2821-9fa9-42c3-a906-041b95626e60",
   "metadata": {},
   "source": [
    "**Exercice: À la lumière de ce graphique, aurait-on avantage à entraîner le réseau plus longtemps?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d94b503-ad0f-4d73-b9c4-9a7f0bbdfe82",
   "metadata": {},
   "source": [
    "L'entraînement a pris un certain temps!\n",
    "Ce ne serait pas une mauvaise idée de sauvegarder notre modèle.\n",
    "On peut le faire à l'aide du `state_dict()` de notre modèle, qui emmagasine la valeur des paramètres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e74e015-b815-4157-b8bd-dda0c241b950",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"./trained_mlp.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8ca436-7589-4ffe-8868-30dc70632e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(\"./trained_mlp.pt\", weights_only=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394af65d",
   "metadata": {},
   "source": [
    "## Inférence\n",
    "\n",
    "On peut maintenant tester le modèle sur différents exemple.\n",
    "\n",
    "### Bruit\n",
    "\n",
    "D'abord, on peut voir comment le réseau répond à un bruit uniforme ou gaussien.\n",
    "Le réseau a une confiance un peu élevée pour des images qui ne sont que du bruit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352bc0a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Bruit uniforme\n",
    "X = torch.rand(1, 28, 28, device=device)\n",
    "preds = try_model(X, model)\n",
    "\n",
    "plt.figure(figsize=(6, 3))\n",
    "plt.subplot(1, 2, 1)\n",
    "plot_image(preds.squeeze().detach(), None, X.squeeze().detach())\n",
    "plt.subplot(1, 2, 2)\n",
    "plot_value_array(preds.squeeze().detach(), None)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1385cf9a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Bruit Gaussien\n",
    "X = torch.randn(1, 28, 28, device=device)\n",
    "preds = try_model(X, model)\n",
    "\n",
    "plt.figure(figsize=(6, 3))\n",
    "plt.subplot(1, 2, 1)\n",
    "plot_image(preds.squeeze().detach(), None, X.squeeze().detach())\n",
    "plt.subplot(1, 2, 2)\n",
    "\n",
    "plot_value_array(preds.squeeze().detach(), None)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528b6f71",
   "metadata": {},
   "source": [
    "### Images Fashion MNIST\n",
    "\n",
    "Pour les images de test ou d'entraînement, le réseau fonctionne, mais n'est pas parfait.\n",
    "Certaines images similaires comme des souliers et des sandales sont plus difficiles à distinguer.\n",
    "Les images pixelisées 28x28 et le réseau de neurones pleinement connecté n'aident pas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c07cbd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "i = random.randrange(len(training_data))\n",
    "img, label = training_data[i]\n",
    "preds = try_model(img, model)\n",
    "plt.figure(figsize=(6, 3))\n",
    "plt.subplot(1, 2, 1)\n",
    "plot_image(preds.squeeze().detach(), label, img.squeeze().detach())\n",
    "plt.subplot(1, 2, 2)\n",
    "plot_value_array(preds.squeeze().detach(), label)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca801b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "i = random.randrange(len(test_data))\n",
    "img, label = test_data[i]\n",
    "preds = try_model(img, model)\n",
    "plt.figure(figsize=(6, 3))\n",
    "plt.subplot(1, 2, 1)\n",
    "plot_image(preds.squeeze().detach(), label, img.squeeze().detach())\n",
    "plt.subplot(1, 2, 2)\n",
    "plot_value_array(preds.squeeze().detach(), label)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe32620-4a62-4833-b9bc-91b11555c7bc",
   "metadata": {},
   "source": [
    "**Exercice: Répétez les deux cellules ci-dessus quelques fois pour voir comment le réseau répond à différents exemples.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b47a74",
   "metadata": {},
   "source": [
    "Les images MNIST proviennent toutes d'une même source. On peut tester avec des images de vêtement\n",
    "obtenues sur internet.\n",
    "\n",
    "On peut aussi essayer de déjouer le réseau en lui donnant une image qui ne correspond à aucune catégorie.\n",
    "Dans tous les cas, pour utiliser une image quelconque, il faut la formatter correctement.\n",
    "\n",
    "On commence par importer l'image avec opencv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86bb81ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "me = cv2.imread(\"photo_thomas_vandal.jpg\", 0)  # 0 pour avoir une image \"grayscale\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf76825",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.imshow(me, cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f92db040",
   "metadata": {},
   "source": [
    "Les images MNIST sont centrées et carrées avec une taille définie. Il faut formatter notre image de façon semblable.\n",
    "La transformation `ToTensor()` normalise l'image et convertit sous forme de tenseur.\n",
    "Une image non normalisée ne sera pas analysée correctement par le réseau, comme nos donnnées d'entraînement étaient normalisées\n",
    "\n",
    "**Exercice: Remarquez la dernière ligne de la cellule suivante. À quoi sert-elle? Testez l'inférence sans cette ligne.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc56b07",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_ax = int(me.shape[0] < me.shape[1])  # Trouver le plus grand axe d'une image rectangulaire\n",
    "min_ax = int(not max_ax)  # Trouver le plus petit axe\n",
    "max_axl = me.shape[max_ax]  # Dimension max\n",
    "min_axl = me.shape[min_ax]  # Dimension min\n",
    "ind = [slice(None), slice(None)]  # Indice pour tous les élément\n",
    "ind[max_ax] = slice(max_axl // 2 - min_axl // 2, max_axl // 2 + min_axl // 2)  # Indice pour l'axe maximum\n",
    "me_sq = me[tuple(ind)]  # On coupe l'image à un carré\n",
    "me_lowres = cv2.resize(me_sq, (28, 28))  # On dégrade la résolution à 28x28\n",
    "img2tensor = ToTensor()  # On convertit en tenseur\n",
    "me_tensor = img2tensor(me_lowres)\n",
    "me_tensor = 1 - me_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827158da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.imshow(me_tensor.squeeze().detach(), cmap=\"binary\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ecace0",
   "metadata": {},
   "source": [
    "Après, on peut tester la prédiction du modèle sur l'exemple\n",
    "Encore une fois, le modèle affiche une certaine confiance vers une valeur spécifique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd576068",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "preds = try_model(me_tensor, model)\n",
    "plt.figure(figsize=(6, 3))\n",
    "plt.subplot(1, 2, 1)\n",
    "plot_image(preds.squeeze().detach(), None, me_tensor.squeeze().detach(), cmap=\"binary\")\n",
    "plt.subplot(1, 2, 2)\n",
    "plot_value_array(preds.squeeze().detach(), None)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d56ad65",
   "metadata": {},
   "source": [
    "On peut répéter l'inférence avec n'importe quelle image ensuite.\n",
    "\n",
    "Définissons une fonction qui répète les opérations ci-dessus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ae1054-c77e-469e-ae69-2ebe59f48ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(fpath, inv=False):\n",
    "\n",
    "    img = cv2.imread(fpath, 0)\n",
    "\n",
    "    max_ax = int(img.shape[0] < img.shape[1])\n",
    "    min_ax = int(not max_ax)\n",
    "    max_axl = img.shape[max_ax]\n",
    "    min_axl = img.shape[min_ax]\n",
    "    ind = [slice(None), slice(None)]\n",
    "    ind[max_ax] = slice(max_axl // 2 - min_axl // 2, max_axl // 2 + min_axl // 2)\n",
    "    img_sq = img[tuple(ind)]\n",
    "    img_lowres = cv2.resize(img_sq, (28, 28))\n",
    "    img2tensor = ToTensor()\n",
    "    img_tensor = img2tensor(img_lowres)\n",
    "    if inv:\n",
    "        img_tensor = 1 - img_tensor\n",
    "\n",
    "    return img_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581634f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Ce t-shirt est plus petit au centre de l'image. ça n'aide surement pas. Et il a un motif\n",
    "dior = load_image(\"dior.jpg\", inv=True)\n",
    "preds = try_model(dior, model)\n",
    "plt.figure(figsize=(6, 3))\n",
    "plt.subplot(1, 2, 1)\n",
    "plot_image(preds.squeeze().detach(), None, dior.squeeze().detach(), cmap=\"binary\")\n",
    "plt.subplot(1, 2, 2)\n",
    "plot_value_array(preds.squeeze().detach(), None)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe1289f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pants = load_image(\"pants.png\")\n",
    "preds = try_model(pants, model)\n",
    "plt.figure(figsize=(6, 3))\n",
    "plt.subplot(1, 2, 1)\n",
    "plot_image(preds.squeeze().detach(), inv_labels_map[\"Trouser\"], pants.squeeze().detach(), cmap=\"binary\")\n",
    "plt.subplot(1, 2, 2)\n",
    "plot_value_array(preds.squeeze().detach(), inv_labels_map[\"Trouser\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a3696f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ts_black = load_image(\"ts_black.png\")\n",
    "preds = try_model(ts_black, model)\n",
    "plt.figure(figsize=(6, 3))\n",
    "plt.subplot(1, 2, 1)\n",
    "plot_image(preds.squeeze().detach(), inv_labels_map[\"T-Shirt\"], ts_black.squeeze().detach(), cmap=\"binary\")\n",
    "plt.subplot(1, 2, 2)\n",
    "plot_value_array(preds.squeeze().detach(), inv_labels_map[\"T-Shirt\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a2e88a",
   "metadata": {},
   "source": [
    "Certaines images font avoir une intensité inverse aux données d'entraînement: on veut s'assurer de les formatter comme il faut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55443bfb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ts_black = load_image(\"ts_black.png\", inv=True)\n",
    "preds = try_model(ts_black, model)\n",
    "plt.figure(figsize=(6, 3))\n",
    "plt.subplot(1, 2, 1)\n",
    "plot_image(preds.squeeze().detach(), inv_labels_map[\"T-Shirt\"], ts_black.squeeze().detach(), cmap=\"binary\")\n",
    "plt.subplot(1, 2, 2)\n",
    "plot_value_array(preds.squeeze().detach(), inv_labels_map[\"T-Shirt\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1679d4b-edd1-4489-b252-2356c362b895",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Voilà! En résumé nous avons:\n",
    "\n",
    "- Appris à importer des images via PyTorch.\n",
    "- Appris à définir un réseau neuronal pleinement connecté.\n",
    "- Appris à entraîner ce réseau via une descente de gradient stochastique.\n",
    "- Appris à utiliser ce réseau pour prédire la valeur de différentes images.\n",
    "\n",
    "Plusieurs de ces éléments reviendront au cours de la session, notamment dans le TP sur les CNNs et dans le devoir 3."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "phy3051",
   "language": "python",
   "name": "phy3051"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
