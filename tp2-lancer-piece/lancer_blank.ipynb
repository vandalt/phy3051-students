{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f9dc378",
   "metadata": {},
   "source": [
    "# Exemple d'estimation d'un seul paramètre: biais d'une pièce de monnaie\n",
    "\n",
    "Dans ce TP, nous allons explorer l'exemple 1 du livre Sivia & Skilling, présenté dans la section 2.1.\n",
    "L'exemple présente l'inférence du biais F d'une pièce de monnaie en faveur du côté face."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b74b1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable, Optional\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Thomas est daltonien\n",
    "plt.style.use(\"tableau-colorblind10\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe3e9b0",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "## Implémentation du modèle\n",
    "\n",
    "Commençons par implémenter le modèle tel que vu en classe.\n",
    "Le _prior_ est uniforme, avec comme équation\n",
    "\n",
    "$$\n",
    " P(F) =\n",
    "   \\begin{cases}\n",
    "     1 & \\text{si } 0 \\leq F \\leq 1,\\\\\n",
    "     0 & \\text{ailleurs}.\\\\\n",
    "   \\end{cases}\n",
    "$$\n",
    "\n",
    "**Codez le prior pour qu'il puisse appliquer cette condition à un tableau.**\n",
    "\n",
    "<details>\n",
    "<summary>Indice</summary>\n",
    "<br>\n",
    "Utilisez `np.where()`\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628b5d37",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "def prior_uniform(\n",
    "    f: np.ndarray[float], a: float = 0.0, b: float = 1.0\n",
    ") -> np.ndarray[float]:\n",
    "    \"\"\"Prior uniforme entre a et b\n",
    "\n",
    "    :param f: Valeurs du paramètre f\n",
    "    :param a: Borne inférieure (min)\n",
    "    :param b: Borne supérieure (max)\n",
    "    :return: Valeur du prior 1/(b-a) ou 0\n",
    "    \"\"\"\n",
    "    # TODO: Compléter\n",
    "\n",
    "\n",
    "f_vals = np.linspace(-0.1, 1.1, num=1000)\n",
    "y_prior = prior_uniform(f_vals)\n",
    "plt.figure(figsize=(7, 5))\n",
    "plt.plot(f_vals, y_prior)\n",
    "plt.xlabel(\"Bias envers face F\")\n",
    "plt.ylabel(\"Prior $p(F)$\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c91969-9250-4cf4-beed-8c40f6dfe028",
   "metadata": {},
   "source": [
    "La vraisemblance est quant à elle donnée par\n",
    "\n",
    "$$\n",
    "P(D|F) \\propto F^{R} (1 - F)^{N - R}.\n",
    "$$\n",
    "\n",
    "La fonction ci-dessous implémente la vraisemblance.\n",
    "Remarquez que la vraisemblance n'est pas bornée entre 0 et 1, car elle ne tient pas compte du _prior_.\n",
    "\n",
    "**Codez la vraisemblance et faites un graphique en fonction de F**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea2bd4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def likelihood(f: np.ndarray[float], r: int, n: int) -> np.ndarray[float]:\n",
    "    \"\"\"Vraisemblance binomiale pour le biais F\n",
    "\n",
    "    :param f: Valeur du paramètre F\n",
    "    :param r: Nombre de lancers ayant donné \"face\"\n",
    "    :param n: Nombre total de lancers\n",
    "    :return: Valeur de la vraisemblance\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "r_demo, n_demo = 5, 10\n",
    "# TODO: Afficher un exemple en graphique en fonction de F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf7518e-a03f-4014-b7f1-81a30915d7ae",
   "metadata": {},
   "source": [
    "Le _posterior_ est donné par le produit du _prior_ et de la vraisemblance.\n",
    "\n",
    "**Codez le posterior**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df13c894",
   "metadata": {},
   "outputs": [],
   "source": [
    "def posterior(f: np.ndarray[float], r: int, n: int, prior_fn: Callable = prior_uniform) -> np.ndarray[float]:\n",
    "    \"\"\"Posterior pour F\n",
    "\n",
    "    :param f: Valeur du paramètre F\n",
    "    :param r: Nombre de lancers ayant donné \"face\"\n",
    "    :param n: Nombre total de lancers\n",
    "    :return: Valeur de la vraisemblance\n",
    "    \"\"\"\n",
    "    # TODO: Completer\n",
    "    \n",
    "\n",
    "\n",
    "r_demo, n_demo = 5, 10\n",
    "plt.figure(figsize=(7, 5))\n",
    "plt.plot(f_vals, posterior(f_vals, r_demo, n_demo))\n",
    "plt.xlabel(\"Bias envers face F\")\n",
    "plt.ylabel(\"Posterior $p(F|R)$\")\n",
    "plt.title(f\"Exemple pour r={r_demo}, n={n_demo}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb7b45a",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "Dans chaque cellule ci-dessus, vous pouvez varier `r_demo` et `n_demo` pour voir comment ces valeurs affectent les distributions.\n",
    "\n",
    "## Simulation des données\n",
    "\n",
    "Nous allons maintenant simuler des données pour un certain nombre de lancers d'une pièce de monnaie.\n",
    "Pour ce faire, nous aurons besoin de définir le vrai biais de la pièce `f_true`.\n",
    "Nous pourrions simuler les lancers directement avec la fonction `binom` de `np.random`.\n",
    "Par contre, une version itérative de la simulation nous permettra de toujours arriver au même résultat avec un `seed` donné et de progressivement ajouter des lancers dans les sections qui suivent.\n",
    "\n",
    "**Codez une boucle qui simule les lancers avec une fraction f_true de \"face\"**\n",
    "\n",
    "**Retournez le nombre de \"face\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e95db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(f_true: float, n: int, seed: Optional[int] = None) -> int:\n",
    "    \"\"\"Simulation des lancers d'une pièce de monnaie biaisée\n",
    "\n",
    "    :param f_true: Biais de la pièce en faveur de face.\n",
    "    :param n: Nombre de lancers.\n",
    "    :param seed: Seed pour le générateur de nombres aléatoires\n",
    "    :return: Nombre de lancers ayant donné \"face\"\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed=seed)\n",
    "\n",
    "    # TODO: Completer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50fabe20",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 3\n",
    "f_true = 0.5\n",
    "r_test = run_experiment(f_true, N)\n",
    "\n",
    "f_post = posterior(f_vals, r_test, N)\n",
    "plt.plot(f_vals, f_post)\n",
    "plt.title(f\"Posterior pour $N={N}$ et $F_\\\\text{{true}}={f_true}$\")\n",
    "plt.xlabel(\"Bias envers face F\")\n",
    "plt.ylabel(\"Posterior $p(F|R)$\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70eb9d7",
   "metadata": {},
   "source": [
    "## Inférence en fonction du nombre de lancers\n",
    "On peut effectuer l'inférence bayesienne pour différents nombres de lancers afin de voir comment les résultats convergent.\n",
    "Pour N = 0, on s'attend à obtenir uniquement le _prior_.\n",
    "Ensuite, plus on ajoute de lancers (données), plus le _posterior_ devrait se rapprocher de la vraie valeur.\n",
    "Nous allons reproduire la figure 2.1 du livre avec le code ci-dessous.\n",
    "Comme la vraisemblance contient une exponentielle, on pourrait avoir des _overflows_ lorsque le nombre de lancers est grand.\n",
    "Pour pallier à ce problème, nous allons utiliser le log de la vraisemblance, le normaliser, puis reconvertir via une exponentiation.\n",
    "Notez que la normalisation ne dérange pas dans ce cas-ci, car ce n'est qu'une exporation de paramètres), nous allons donc seulement diviser par le maximum avant d'afficher pour faciliter la visualisation.\n",
    "\n",
    "**Codez la vraisemblance en utilisant ces équations. Votre fonction doit retourner p_2**\n",
    "\n",
    "$$\n",
    "L = \\ln p(D|F) = R \\ln f + (N - R) \\ln (1-f)\n",
    "$$\n",
    "\n",
    "$$\n",
    "c = \\mathrm{max}(L)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mathrm{LSE} = c + \\ln{(\\sum e^{L - c})}\n",
    "$$\n",
    "\n",
    "$$\n",
    "p_2(D|F) = e^{L - LSE}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e585aa-6fca-4ad8-bff4-57d61a81327b",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "def likelihood(f: np.ndarray[float], r: int, n: int) -> np.ndarray:\n",
    "    \"\"\"Vraisemblance normalisée via le \"log-sum-exp\"\n",
    "\n",
    "    :param f: Valeur du paramètre F\n",
    "    :param r: Nombre de lancers ayant donné \"face\"\n",
    "    :param n: Nombre total de lancers\n",
    "    :return: Vraisemblance\n",
    "    \"\"\"\n",
    "    # TODO: Utilier le \"log-sum-exp\" pour calculer la vraisemblance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343601f2-6d25-4ddd-bbd3-e33bd6d0a292",
   "metadata": {},
   "source": [
    "**Complétez les TODO pour simuler les données et calculer le _posterior_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199c912e-8cf5-4004-98b3-849e29016e4e",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "N_values = 2 ** np.arange(13)\n",
    "N_values = np.sort(np.append(N_values, [0, 3]))\n",
    "ncols = 3\n",
    "nrows = int(np.ceil(len(N_values) / ncols))\n",
    "\n",
    "\n",
    "f_vals = np.linspace(1e-5, 0.9999, num=1000)\n",
    "f_true = 0.25\n",
    "seed = 3051\n",
    "fig, axes = plt.subplots(nrows, ncols, figsize=(6, 8))\n",
    "for i in range(len(N_values)):\n",
    "    ax = axes.ravel()[i]\n",
    "    Ni = N_values[i]\n",
    "    # TODO: Simuler les données (n'oubliez pas le seed)\n",
    "    # TODO: Calculez le posterior pour ce nombre de lancers\n",
    "    # TOOD: Utilisez ax.plot() pour afficher le résultat\n",
    "    ax.set_xlim(0, 1)\n",
    "    ax.set_yticks([])\n",
    "    ax.set_xlabel(\"Bias envers face F\")\n",
    "    ax.set_ylabel(\"$p(F|R)$\")\n",
    "    ax.text(0.8, 0.87, f\"N={Ni}\", horizontalalignment=\"center\", transform=ax.transAxes)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51dd0738-733f-4a55-8e90-14368461f5fe",
   "metadata": {},
   "source": [
    "## Test de différents _priors_\n",
    "\n",
    "Nous allons maintenant reproduire la section 2.1.1. du livre.\n",
    "Nous utiliserons un _prior_ Gaussien qui assume une pièce normale et un _prior_ \"Vegas\" qui assume une pièce biaisée.\n",
    "\n",
    "$$\n",
    "p_G(F) = \\frac{1}{\\sqrt{2 \\pi}\\sigma} e^{(F - \\mu)^2 / 2 \\sigma^2},\n",
    "$$\n",
    "\n",
    "où on utilise $\\mu=0.5$ et $\\sigma=0.05$.\n",
    "\n",
    "$$\n",
    "p_V(F) = e^{- b f} + e^{b (f - 1)},\n",
    "$$\n",
    "\n",
    "avec $b = 20$.\n",
    "\n",
    "**Codez ces deux priors et affichez les avec le prior uniforme. \"Normalisez\" les priors pour que leur maximum soit égal à 1.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09fb9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prior_gauss(f: np.ndarray[float], mu:float=0.5, sd: float=0.05) -> np.ndarray[float]:\n",
    "    # TODO: Prior gaussien\n",
    "\n",
    "\n",
    "def prior_vegas(f: np.ndarray[float], b: float=20.0) -> np.ndarray[float]:\n",
    "    # TODO: Exponentielle\n",
    "\n",
    "\n",
    "# TODO: Afficher les priors\n",
    "f_vals = np.linspace(-0.1, 1.1, num=1000)\n",
    "fig = plt.figure(figsize=(7, 5))\n",
    "plt.xlabel(\"Bias envers face F\")\n",
    "plt.ylabel(\"Prior $p(F)$\")\n",
    "fig.legend(bbox_to_anchor=(1.1, 0.9))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc7786d-fc6e-45fc-aba3-f7141e66d494",
   "metadata": {},
   "source": [
    "**Répétez l'expérience pour différents N comme ci-dessus pour reproduire la figure, mais cette fois avec les posteriors pour chaque prior. Utilisez l'argument `prior_fn`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b5e8cf-d12e-411b-bbee-6c30d494ea1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Répéter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e041cb-738d-4018-949a-93a5fadf34b9",
   "metadata": {},
   "source": [
    "On peut voir que le _prior_ \"Vegas\" converge assez rapidement à la même conclusion que le _prior_ uniforme.\n",
    "Ceci n'est pas trop surprenant: une fois les extrémités éliminées, le _prior_ \"Vegas\" est plutôt plat.\n",
    "Pour ce qui est du prior Gaussien, on peut voir qu'il prend beaucoup plus de temps à converger vers la bonne solution en raison de la forte préférence initiale pour une pièce non biaisée.\n",
    "\n",
    "## Exemple réaliste: une seule expérience\n",
    "\n",
    "Nous pouvons maintenant faire un exemple réaliste avec une seule expérience et faire une analyse complète.\n",
    "\n",
    "1. Simuler l'expérience avec `f_true = 0.35` et `N=20`.\n",
    "2. Calculer la distribution _posterior_.\n",
    "3. Calculer l'évidence.\n",
    "4. Normaliser la distribution _posterior_.\n",
    "5. Calculer la moyenne, la médiane et la valeur maximale du posterior\n",
    "6. Affichez ces valeurs sur le graphqieu\n",
    "7. Calculez la valeur de l'écart type et affichez un intervalle.\n",
    "8. Calculez un intervalle de confiance numérique à 68%."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
