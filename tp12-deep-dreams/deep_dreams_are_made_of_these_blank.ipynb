{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyN+yxl3ImbfRVNyH42F0myN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vandalt/phy3051-students/blob/main/tp12-deep-dreams/deep_dreams_are_made_of_these_blank.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Explorations des représentations dans un CNN\n",
        "\n",
        "Avant de plonger dans les modèles génératifs, je me disais qu'il serait intéressant de réviser certains concepts avec les CNNs, notamment les représentations que le réseau se fait d'une image.\n",
        "\n",
        "Le notebook fonctionne sur CPU, mais est un peu lent. Je suggère d'utiliser un runtime Colab avec GPU.\n",
        "Si seulement des CPUs sont disponibles, vous pouvez réduire le nombre d'itérations pour accélérer le debugging."
      ],
      "metadata": {
        "id": "O1XNf6YJD2Wy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision import models, transforms\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(device)"
      ],
      "metadata": {
        "id": "a1pvilHCEviA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importation du modèle\n",
        "\n",
        "Comme au TP sur les VIT, on peut utiliser un modèle PyTorch pré-entraîné.\n",
        "On peut tester deux réseaux, VGG et AlexNet.\n",
        "N'hésitez pas à explorer d'autres architectures également."
      ],
      "metadata": {
        "id": "YIaqNBumHU1r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"vgg19\"  # vgg19, alexnet\n",
        "\n",
        "if model_name == \"alexnet\":\n",
        "    weights = models.AlexNet_Weights.DEFAULT\n",
        "    model = models.alexnet(weights=weights)\n",
        "elif model_name == \"vgg19\":\n",
        "    weights = models.VGG19_Weights.DEFAULT\n",
        "    model = models.vgg19(weights=weights)\n",
        "model = model.to(device)\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "1GA9VirwEzBN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercice: Affichez le nombre de paramètres dans le modèle et extrayez les catégories des poids pré-entraînés. Créez deux dictionnaires: idx2label et label2idx pour convertir les indices en noms de classes et vice-versa.**"
      ],
      "metadata": {
        "id": "vxd2_XtD6HUd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Exercice"
      ],
      "metadata": {
        "id": "Fn9soCmlFLLa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importation d'une image\n",
        "\n",
        "Comme nous avons vu au dernier TP, on peut importer une image trouvée en ligne.\n",
        "Contrairement à Huggingface, avec PyTorch if faudra la télécharger manuellement."
      ],
      "metadata": {
        "id": "KQP5xlrdHZh3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import io\n",
        "import requests\n",
        "from PIL import Image\n",
        "\n",
        "image_name = \"sky\"  # dog ou sky\n",
        "\n",
        "if image_name == \"dog\":\n",
        "    url = \"https://storage.googleapis.com/download.tensorflow.org/example_images/YellowLabradorLooking_new.jpg\"\n",
        "elif image_name == \"sky\":\n",
        "    url = 'https://s3.amazonaws.com/pbblogassets/uploads/2018/10/22074923/pink-sky-cover.jpg'\n",
        "elif image_name == \"carina\":\n",
        "    url = \"https://www.nasa.gov/wp-content/uploads/2023/03/main_image_star-forming_region_carina_nircam_final-5mb.jpg\"\n",
        "\n",
        "def download_image(url: str) -> Image:\n",
        "    r = requests.get(url)\n",
        "    if r.status_code == 200:\n",
        "        img = Image.open(io.BytesIO(r.content))\n",
        "        return img\n",
        "    else:\n",
        "        r.raise_for_status()"
      ],
      "metadata": {
        "id": "dbp-fxw_FMnK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pil_img = download_image(url)"
      ],
      "metadata": {
        "id": "YFAyqXInGe2Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.imshow(pil_img)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "b33DhI34GqVX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transformation et inférence\n",
        "\n",
        "Comme au TP sur les tranformeurs, on peut d'abord tester notre modèle PyTorch sur l'image trouvée en ligne.\n",
        "Il suffit de transformer l'image dans le bon format, puis de la donner au modèle.\n",
        "\n",
        "**Exercice: extrayez les transformations PyTorch des poids pré-entraînés et transformez l'image PIL en tenseur. Testez ensuite le modèle sur cette image. Affichez les 5 meilleures probabilités et les classes associées.**"
      ],
      "metadata": {
        "id": "ENTXQunpMPtu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Inference"
      ],
      "metadata": {
        "id": "kxaKj4ZRGvVf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exploration des couches du réseau\n",
        "\n",
        "On peut d'abord visualiser le contenu des couches internes du CNN en accédant aux couches de convolution dans la composante `features` du modèle (voir la structure plus haut).\n",
        "\n",
        "Ceci nous permet 1) de faire passer l'image dans certaines couches pour visualiser des sorties intérmédiaires et 2) de visualiser le noyau de convolution appris par cette couche."
      ],
      "metadata": {
        "id": "hv8ycFsiMUvH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Activations\n",
        "\n",
        "Commençons par inspecter les activations du réseau.\n",
        "\n",
        "**Exercice: En accédant aux couches de convolution du réseau (`model.features`), faites passer l'image à travers la première couche de convolution et sa fonction d'activation. Quel est le format de la sortie? Affichez l'image pour l'un des canaux (_channels_).**\n",
        "\n",
        "**Exercice: Une fois que l'exercice ci-dessus est complété, essayer de changer le canal utilisé. Essayez également d'inspecter la sortie d'une couche plus profonde dans le réseau.**"
      ],
      "metadata": {
        "id": "HY6VVTaXzO9u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Activations"
      ],
      "metadata": {
        "id": "jfKUltN3IkNB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Noyau de convolution\n",
        "\n",
        "**Exercice: Inspectez maintenant le ou les noyaux de convolutions de votre choix. Affichez le avec imshow. Ceci nécessite d'accéder aux paramètres de la couche de convolution et de comprendre leur format.**"
      ],
      "metadata": {
        "id": "DcuANhg6zSfu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Noyaux"
      ],
      "metadata": {
        "id": "LRde8q9vKvS4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mécanisme de \"hooks\"\n",
        "\n",
        "Au lieu de faire passer l'image manuellement jusqu'à la N-ième couche, il est possible de définir un \"hook\" qui ajoutera la sortie de la couche d'intérêt à PyTorch.\n",
        "\n",
        "On peut ainsi activer à une ou plusieurs activations intermédiaires en faisant passer l'image dans le réseau au complet."
      ],
      "metadata": {
        "id": "vWVoKlU4zV8A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# NOTE: Pas besoin de nlayer+1 car activation est \"inplace\",\n",
        "# donc ReLU modifie le tenseur rétroactivement\n",
        "target_layer = model.features[nth_layer]\n",
        "activations = {}\n",
        "def hook_fn(m, i, o):\n",
        "    activations[\"output\"] = o\n",
        "hook = target_layer.register_forward_hook(hook_fn)"
      ],
      "metadata": {
        "id": "h6M0Lp8o09_D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercice: Imprimez les clés du dictionnaire `activations`. Appliquez ensuite le modèle à l'image que nous avons téléchargée, puis réimprimez les clés d'`activations`. Affichez ensuite le type et le format (shape) de la valeur contenue dans le dictionnaire.**"
      ],
      "metadata": {
        "id": "aaSbjSc-9rlD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Test hook"
      ],
      "metadata": {
        "id": "kH2x3A6D9wGe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercice: Vérifiez que les activations obtenues via le _hook_ sont égales à celles obtenues manuellement plus haut.**"
      ],
      "metadata": {
        "id": "8tVYL3Bh-hoc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Check hook"
      ],
      "metadata": {
        "id": "2nkWeT8s2Ynm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "On peut ensuite supprimer le _hook_."
      ],
      "metadata": {
        "id": "meyic9Fk-u2s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hook.remove()"
      ],
      "metadata": {
        "id": "IIVPxCa_54tv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Deep dream\n",
        "\n",
        "Essayons maintenant d'implémenter une version simple de DeepDream avec PyTorch.\n",
        "Je mets en référence à la fin du notebook quelques exemples en ligne qui m'ont été utiles pour préparer ce notebook et qui contiennent plus d'information.\n",
        "\n",
        "Le concept du DeepDream est assez simple. On traite l'image comme les paramètres et on traite les activations comme les \"données\". La fonction objectif $L$ peut être, par exemple la norme des activations. Au lieu de la minimiser, on la maximise. Pour une image $x$, on a donc\n",
        "\n",
        "$$\n",
        "x \\leftarrow x + \\alpha \\nabla_x L(a)\n",
        "$$\n",
        "\n",
        "où $\\alpha$ est un hyperparamètre de taux d'apprentissage.\n",
        "$L$ pourait être la norme L2 des activations d'une couche, d'un seul canal, ou encore l'activation d'une seule classe à la sortie du réseau. Nous commecerons par implémenter la norme L2 des activations d'une couche.\n",
        "\n",
        "**Exercice: Implémetez le DeepDream en PyTorch. Utilisez l'image téléchargée comme point de départ et effectuez 20 itérations avec $\\alpha = 1$ pour la couche 26 des `features`.**\n",
        "\n",
        "<details>\n",
        "\n",
        "<summary>Cliquez pour des indications plus détaillées</summary>\n",
        "\n",
        "Je suggère de séparer le code en deux fonctions:\n",
        "\n",
        "- Une fonction `deep_dream(x, model, target_layer, niter, lr=1.0)` qui:\n",
        "    - Clone l'image `x`\n",
        "    - Active le gradient de l'image avec `requires_grad_()`\n",
        "    - Enregistre un _hook_ sur `target_layer`\n",
        "    - Itère le calcul du gradient et l'ascenscion de gradient via la fonction `get_gradient()` définie ci-dessous et une mise à jour des donées. `x.data` et `gradient.data` seront utiles ici.\n",
        "    - Supprime le `hook`\n",
        "    - Désactive le gradient de l'image avec `requires_grad_()`\n",
        "    - Retourne l'image modifiée\n",
        "- Une fonction `get_gradient(x, model)` qui:\n",
        "    - Remet le gradient du modèle à 0\n",
        "    - Passe l'image `x` dans le modèle\n",
        "    - Accède aux activations d'intérêt via le dictionnaire du _hook_\n",
        "    - Calcule fonction objectif (norme des activations)\n",
        "    - Fait la rétropropagation\n",
        "\n",
        "</details>"
      ],
      "metadata": {
        "id": "yKKsRSoRLuBI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Deep dream"
      ],
      "metadata": {
        "id": "1MykO9be42oq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "La fonction `postprocess` ci-dessous fait l'inverse de la normalisation pour repasser en images RGB sur 0-255 avec des unint8.\n",
        "\n",
        "**Exerice: Affichez le résultat**"
      ],
      "metadata": {
        "id": "z-LOI3HeDPOi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def postprocess(img_tensor: torch.Tensor):\n",
        "    denorm = transforms.Compose([\n",
        "        transforms.Normalize(mean = [ 0., 0., 0. ], std = [ 1/0.229, 1/0.224, 1/0.225 ]),\n",
        "        transforms.Normalize(mean = [ -0.485, -0.456, -0.406 ], std = [ 1., 1., 1. ]),\n",
        "    ])\n",
        "    img_arr = denorm(img_tensor).detach().cpu().permute(1, 2, 0).numpy()\n",
        "    img_arr = np.uint8(np.clip(img_arr, 0, 1) * 255)\n",
        "    return Image.fromarray(img_arr)\n",
        "\n",
        "dream_img = postprocess(dream_tensor)\n",
        "plt.imshow(dream_img)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "sUfDz2YNAJ48"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercice: Modifiez votre code pour que la fonction d'activation puisse soit la norme L2 soit la valeur des activations. Modifiez la également pour que le canal de `target_layer` puisse être spécifié. Testez l'optimisation pour une des classes. Vous pouvez modifier l'image téléchargée pour `sky` et ré-exécuter le notebook.**"
      ],
      "metadata": {
        "id": "LbHg2xVNDv5A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Deep dream optimize class"
      ],
      "metadata": {
        "id": "40e3T7nyAdpb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercice: Ajoutez un `roll` aléatoire dans votre fonction via un argument boolean `roll`. Testez la fonction avec untaux d'apprentissage de 0.2 et 50 époques, pour la couche 26 des features.**"
      ],
      "metadata": {
        "id": "_6Rt3bKSEdIr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Roll"
      ],
      "metadata": {
        "id": "BpHakKClB7_W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Un autre concept qu'on voit souvent avec le DeepDream est celui d'octaves: on répète le DeepDream en changeant la taille de l'image. Typiquement, à partir de la taille initiale, on définit une liste de puissances `n` et on répète l'opération avec:\n",
        "\n",
        "```\n",
        "new_shape = base_shape * octave_scale**n\n",
        "```\n",
        "\n",
        "**Pour `octave_scale=1.3`, explorez des puissances entre -2 et 3.**"
      ],
      "metadata": {
        "id": "_-QxBtbvE2pE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Octave"
      ],
      "metadata": {
        "id": "2sNhOxjDLE-5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercice: Testez les octaves en tentant d'optimiser une classe.**"
      ],
      "metadata": {
        "id": "vdczJdVxGTyC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Octave classe"
      ],
      "metadata": {
        "id": "W4hoEMdOGWro"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# décommenter pour chercher des classes à essayer\n",
        "#idx2label"
      ],
      "metadata": {
        "id": "d6wkx_xqLfuN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercice: Testez une image aléatoire comme point de départ**"
      ],
      "metadata": {
        "id": "QhqCc9gOGba1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Random images"
      ],
      "metadata": {
        "id": "EBZrEvVP_Vaw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Références\n",
        "\n",
        "- [Article de blog Google Research sur Deep Dream](https://research.google/blog/inceptionism-going-deeper-into-neural-networks/)\n",
        "- [Blog sur la \"Deep Visualization\"](https://yosinski.com/deepvis)\n",
        "- [Exemple Tensorflow avec le modèle Inception V3](https://www.tensorflow.org/tutorials/generative/deepdream)\n",
        "- [Implémentation simple en PyTorch](https://github.com/juanigp/Pytorch-Deep-Dream/blob/master/Deep_Dream.ipynb)\n",
        "- [Implémentation plus complexe en PyTorch](https://github.com/gordicaleksa/pytorch-deepdream/blob/master/The%20Annotated%20DeepDream.ipynb)"
      ],
      "metadata": {
        "id": "4x_6LimINRNu"
      }
    }
  ]
}