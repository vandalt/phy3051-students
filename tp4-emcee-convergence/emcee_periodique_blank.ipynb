{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34ef12ad",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "# Exemple emcee\n",
    "\n",
    "Dans ce notebook, nous utiliserons _emcee_ pour échantillonner la distribution a posteriori d'un modèle périodique à 5 paramètres.\n",
    "\n",
    "## Génération de fausses données\n",
    "\n",
    "Nous allons d'abord générer des données pour les utiliser dans l'exemple.\n",
    "Les données seront générées avec une fonction sinus. On ajoute ensuite un bruit gaussien aux valeurs. On ajoute un terme de bruit additionnel qui n'est pas inclut dans les barres d'erreurs. Le but est d'explorer une situation où les barres d'erreurs sont sous-estimées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c32edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(123)  # Pour toujours avoir les mêmes valeurs random\n",
    "\n",
    "# Définition des vrais paramètres\n",
    "amp_true = 1.6\n",
    "per_true = 0.7\n",
    "phi_true = 1.1\n",
    "off_true = 0.2\n",
    "sigma_true = 0.2\n",
    "truths =  [\n",
    "    np.log(amp_true),\n",
    "    per_true,\n",
    "    phi_true,\n",
    "    off_true,\n",
    "    np.log(sigma_true),\n",
    "]\n",
    "\n",
    "npts = 50\n",
    "t = np.sort(2 * per_true * np.random.rand(npts))\n",
    "y_true = amp_true * np.sin(2*np.pi * t / per_true + phi_true) + off_true\n",
    "yerr = amp_true * 0.01 + 0.15 * amp_true * np.random.rand(npts)\n",
    "y = y_true + yerr * np.random.randn(npts) + sigma_true * np.random.randn(npts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a441dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.errorbar(t, y, yerr=yerr, fmt=\"k.\", label=\"Données\")\n",
    "plt.xlabel(\"t\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e22fb5",
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": []
   },
   "source": [
    "## Définition du problème\n",
    "\n",
    "Une fois que les données sont connues, il est temps de formuler le problème pour l'analyse MCMC.\n",
    "\n",
    "On définit d'abord notre modèle qui permet de générer les valeurs de $y$ pour une série de valeurs $t$ (ou `t` dans le code). Les paramètres sont dénotés par `theta`.\n",
    "\n",
    "La fonction de vraisemblance est une probablité gaussienne et les priors sont tous uniforme.\n",
    "Remarquez le paramètre $s$. Il s'agit d'un bruit gaussien ajouté en quadrature aux barres d'erreur dans la vraisemblance. Si les barres d'erreurs sont sous-estimées par rapport au bruit présent dans les données, ce paramètre devrait être non nul.\n",
    "Pour tenir compte de ce paramètre, il suffit de l'ajouter (en quadrature) aux barres d'erreur dans le calcul de la vraisemblance. Ce paramètre ne doit pas être \"passé\" au modèle `model`.\n",
    "\n",
    "Afin d'avoir un _prior_ log-uniforme sur l'amplitude et le bruit additionnel, on utilise le log des paramètres avec un _prior_ uniforme. C'est une alternative valable à l'utilisation d'un prior log-uniforme sur le paramètre directement.\n",
    "\n",
    "La distribution « posterior » n'est qu'une multiplication du prior par la vraisemblance: l'évidence n'est pas utilisée avec `emcee`.\n",
    "Le prior est généralement moins couteux en temps de calcul. C'est pourquoi on calcule d'abord le prior, puis on calcule la vraisemblance uniquement si le prior est non nul.\n",
    "\n",
    "Toutes les distributions seront sous forme logarithmique. Ceci aide à la stabilité numérique et l'exploration efficace de l'espace-paramètres."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8c8361-438e-46ae-b099-71459a47087b",
   "metadata": {},
   "source": [
    "**Exercice: implémentez les fonctions pour le modèle, le log-likelihood, le log-prior et log-posterior.** Pour le prior, je suggère d'implémenter une fonction de prior uniforme (en log) et de la réutiliser pour tous les paramètres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a260db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(t, theta):\n",
    "    \"\"\"\n",
    "    - t: tableau de temps\n",
    "    - theta: vecteur de paramètres [log(A), P, phi, C]\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "def log_likelihood(theta, t, y, yerr):\n",
    "    \"\"\"\n",
    "    - theta: vecteur de paramètres [log(A), P, phi, C, log(s)]\n",
    "    - t: tableau de temps\n",
    "    - y: tableau de valeurs y\n",
    "    - yerr: tableau des erreurs en y\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "def uniform_log_prior(pval, minval, maxval):\n",
    "    \"\"\"\n",
    "    Logarithme d'un prior uniforme\n",
    "    (Note: ceci est différent d'un prior uniforme sur le log du paramètre).\n",
    "    - pval: Valeur du paramètre\n",
    "    - minval: Borne inféreure\n",
    "    - maxval: Borne supérieure\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "def log_prior(theta):\n",
    "    \"\"\"\n",
    "    Log-prior total sur les paramètres.\n",
    "    Utilisez la fonction uniform_log_prior ci-dessus.\n",
    "    - theta: vecteur de paramètres [log(A), P, phi, C, log(s)]\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "def log_posterior(theta, t, y, yerr):\n",
    "    \"\"\"\n",
    "    - theta: vecteur de paramètres [log(A), P, phi, C, log(s)]\n",
    "    - t: tableau de temps\n",
    "    - y: tableau de valeurs y\n",
    "    - yerr: tableau des erreurs en y\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03cd77fc",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "## Test du modèle\n",
    "\n",
    "On peut maintenant tester le modèle pour explorer à l'oeil quelques valeurs de paramètres et s'assurer que le modèle correspond environ aux données.\n",
    "\n",
    "**Exercice: Testez différentes valeurs de paramètres (`pguess`) et évaluez le modèle. Choisissez ainsi une valeur de départ plausible pour le MCMC.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331b9827",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "387847c7-0e3d-4d12-a40e-76abda962d3a",
   "metadata": {},
   "source": [
    "## MCMC avec emcee\n",
    "\n",
    "Il est maintenant temps d'estimer les valeurs de chaque paramètre avec `emcee`. \n",
    "\n",
    "**Exercice: implémentez un MCMC avec les paramètres suivants:**\n",
    "\n",
    "- 100 walkers (chaînes)\n",
    "- 5000 pas\n",
    "- Positions de départ dans une petite \"balle\" gaussienne autour de la position de départ `pguess` trouvée plus haut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a3202d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import emcee\n",
    "\n",
    "# TODO: MCMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b5279a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2613ce21-7ce3-4434-89bb-81ce58d08053",
   "metadata": {},
   "source": [
    "Un premier diagnostic souvent utile consiste à regarder l'évolution des chaines (tous les « walkers » sont affichés pour chaque paramètre). Ce graphique permet généralement d'identifier le « burn-in » requis.\n",
    "\n",
    "**Exercice affichez les chaînes pour tous les paramètres et déterminez un temps de \"burn-in\" raisonnable. Définissez une variable `nburn` qui vous permettra de rejeter les premiers échantillons pour le reste du Notebook.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ed6ec2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c383601e-6afd-4f31-8045-370b22470a5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fd20694b-a252-4fd9-b682-58c64e36f461",
   "metadata": {},
   "source": [
    "Afin d'évaluer la convergence, on peut calculer le temps d'autocorrélation et s'assurer qu'il est inférieur à $N_{\\text{step}}/50$.\n",
    "\n",
    "**Exercice: calculez le temps d'autocorrélation. N'oubliez pas de rejeter le _burn-in_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58dc6c96-8375-4cdb-91ef-577399f85f45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e00990fd-67eb-4094-9521-637e3768d0cd",
   "metadata": {},
   "source": [
    "Un autre type de graphique utile est le « corner plot ». Ce graphique affiche un histogramme pour chaque paramètre (distribution marginalisée), ainsi que la distribution 2D pour chaque paire de paramètre. On peut ainsi voir les (anti-)corrélations entre certains paramètres.\n",
    "\n",
    "**Affichez le corner plot pour tous les paramètres, affichez les titres, le nom des paramètres, et les quantiles 0.16, 0.5 et 0.84. Explorez les options présente dans `corner`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918ee00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import corner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a63565-e6a5-4d9b-835f-3090b3d5f87c",
   "metadata": {},
   "source": [
    "**Exercice: Affichez 100 échantillons pour le modèle, superposés aux données**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f71463-893b-49d8-ace1-9f9a28046475",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
